{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/cconsta1/dion-bone-classification/blob/main/5fold_strattified_dion.ipynb",
      "authorship_tag": "ABX9TyMjn+Celj27p+kXT79Y1bEi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cconsta1/dion-bone-classification/blob/main/5fold_strattified_dion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Necessary Libraries"
      ],
      "metadata": {
        "id": "W6PiJOHXJulv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Necessary Libraries\n",
        "!pip install xgboost lightgbm openpyxl scikit-learn --quiet"
      ],
      "metadata": {
        "id": "6BxDHT3WJsz1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Required Libraries"
      ],
      "metadata": {
        "id": "O8TNHYKDJ1fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import StratifiedKFold, LeaveOneOut\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import openpyxl\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "print(\"Libraries Imported!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd-crjyDfCzT",
        "outputId": "d3bf2bb1-b4d7-483f-f9a7-eb716856de49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries Imported!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Prepare the Dataset"
      ],
      "metadata": {
        "id": "LI4QU0eoJ7FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define File Paths (Modify as Needed)\n",
        "left_bones_path = \"/content/drive/MyDrive/Dion-data/Cleaned_Left_Bones.csv\"\n",
        "right_bones_path = \"/content/drive/MyDrive/Dion-data/Cleaned_Right_Bones.csv\"\n",
        "\n",
        "# Load Cleaned Datasets\n",
        "df_mf_left_bones = pd.read_csv(left_bones_path)\n",
        "df_mf_right_bones = pd.read_csv(right_bones_path)\n",
        "\n",
        "print(f\"Loaded Left Bones Dataset: {df_mf_left_bones.shape} | Right Bones Dataset: {df_mf_right_bones.shape}\")\n",
        "\n",
        "# Shuffle Datasets\n",
        "df_mf_left_bones = df_mf_left_bones.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_mf_right_bones = df_mf_right_bones.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Encode Target Variable (Pelvis Sex)\n",
        "df_mf_left_bones[\"Pelvis Sex\"] = LabelEncoder().fit_transform(df_mf_left_bones[\"Pelvis Sex\"])\n",
        "df_mf_right_bones[\"Pelvis Sex\"] = LabelEncoder().fit_transform(df_mf_right_bones[\"Pelvis Sex\"])\n",
        "\n",
        "print(\"Cleaned datasets loaded, shuffled, and encoded!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1hHQjj3fCvs",
        "outputId": "a98d2e9e-f79f-4bf7-85ba-211961f84189"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Left Bones Dataset: (48, 38) | Right Bones Dataset: (48, 38)\n",
            "Cleaned datasets loaded, shuffled, and encoded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate and Save Descriptive Statistics\n"
      ],
      "metadata": {
        "id": "zySYMZ1dKAza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file names and corresponding DataFrame selections\n",
        "tables_info = [\n",
        "    (\"Descriptive_Statistics_Left_Bones_Females.xlsx\", df_mf_left_bones[df_mf_left_bones[\"Pelvis Sex\"] == 0]),\n",
        "    (\"Descriptive_Statistics_Left_Bones_Males.xlsx\", df_mf_left_bones[df_mf_left_bones[\"Pelvis Sex\"] == 1]),\n",
        "    (\"Descriptive_Statistics_Right_Bones_Females.xlsx\", df_mf_right_bones[df_mf_right_bones[\"Pelvis Sex\"] == 0]),\n",
        "    (\"Descriptive_Statistics_Right_Bones_Males.xlsx\", df_mf_right_bones[df_mf_right_bones[\"Pelvis Sex\"] == 1])\n",
        "]\n",
        "\n",
        "# Loop through each case and save the descriptive statistics\n",
        "for file_name, df in tables_info:\n",
        "    stats = df.describe().transpose()\n",
        "    stats.to_excel(file_name)\n",
        "    print(f\"Saved: {file_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHyCp7trKzRD",
        "outputId": "4caa2c74-6569-4832-9f6f-9834cf4a136f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: Descriptive_Statistics_Left_Bones_Females.xlsx\n",
            "Saved: Descriptive_Statistics_Left_Bones_Males.xlsx\n",
            "Saved: Descriptive_Statistics_Right_Bones_Females.xlsx\n",
            "Saved: Descriptive_Statistics_Right_Bones_Males.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing Values Per Column - Left Bones Dataset:\")\n",
        "print(df_mf_left_bones.isna().sum())\n",
        "\n",
        "print(\"\\n Missing Values Per Column - Right Bones Dataset:\")\n",
        "print(df_mf_right_bones.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3apucUh8fCkO",
        "outputId": "11ec0661-8fce-4716-8bf9-2a3825e38c34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values Per Column - Left Bones Dataset:\n",
            "Pelvis Sex                                            0\n",
            "Clavicle maximum length                              31\n",
            "Clavicle sagittal diameter at midshaft               30\n",
            "Clavicle vertical diameter at midshaft               30\n",
            "Scapula height                                       42\n",
            "Scapula breadth                                      42\n",
            "Humerus maximum length                               25\n",
            "Humerus epicondylar breadth                          23\n",
            "Humerus vertical diameter of head                    22\n",
            "Humerus maximum diameter at midshaft                 25\n",
            "Humerus minimum diameter at midshaft                 25\n",
            "Radius maximum length                                26\n",
            "Radius sagittal diameter at midshaft                 26\n",
            "Radius transverse diameter at midshaft               26\n",
            "Ulna maximum length                                  40\n",
            "Ulna dorso-volar diameter                            22\n",
            "Ulna transverse diameter                             22\n",
            "Ulna physiological length                            38\n",
            "Ulna minimum circumference                           25\n",
            "Femur maximum heigth                                 19\n",
            "Femur bicondylar length                              20\n",
            "Femur epicondylar breadth                            20\n",
            "Femur maximum head diameter                          14\n",
            "Femur sagittal subtrochanteric diameter               9\n",
            "Femur transverse subtrochanteric diameter             9\n",
            "Femur sagittal midshaft diameter                     20\n",
            "Femur transverse midshaft diameter                   20\n",
            "Femur midshaft circumference                         20\n",
            "Tibia length                                         24\n",
            "Tibia maximum proximal epiphyseal breadth            20\n",
            "Tibia maximum distal epiphyseal breadth              21\n",
            "Tibia maximum diameter at the nutrient foramen       13\n",
            "Tibia transverse diameter at the nutrient foramen    13\n",
            "Tibia circumference at the nutrient foramen          13\n",
            "Fibula maximum length                                34\n",
            "Fibula maximum diameter at midshaft                  34\n",
            "Calcaneus maximum length                             18\n",
            "Calcaneus middle breadth                             20\n",
            "dtype: int64\n",
            "\n",
            " Missing Values Per Column - Right Bones Dataset:\n",
            "Pelvis Sex                                            0\n",
            "Clavicle maximum length                              35\n",
            "Clavicle sagittal diameter at midshaft               33\n",
            "Clavicle vertical diameter at midshaft               33\n",
            "Scapula height                                       45\n",
            "Scapula breadth                                      45\n",
            "Humerus maximum length                               26\n",
            "Humerus epicondylar breadth                          22\n",
            "Humerus vertical diameter of head                    23\n",
            "Humerus maximum diameter at midshaft                 26\n",
            "Humerus minimum diameter at midshaft                 26\n",
            "Radius maximum length                                20\n",
            "Radius sagittal diameter at midshaft                 20\n",
            "Radius transverse diameter at midshaft               20\n",
            "Ulna maximum length                                  27\n",
            "Ulna dorso-volar diameter                            14\n",
            "Ulna transverse diameter                             15\n",
            "Ulna physiological length                            26\n",
            "Ulna minimum circumference                           19\n",
            "Femur maximum heigth                                 16\n",
            "Femur bicondylar length                              16\n",
            "Femur epicondylar breadth                            23\n",
            "Femur maximum head diameter                          10\n",
            "Femur sagittal subtrochanteric diameter               7\n",
            "Femur transverse subtrochanteric diameter             7\n",
            "Femur sagittal midshaft diameter                     14\n",
            "Femur transverse midshaft diameter                   14\n",
            "Femur midshaft circumference                         15\n",
            "Tibia length                                         26\n",
            "Tibia maximum proximal epiphyseal breadth            26\n",
            "Tibia maximum distal epiphyseal breadth              23\n",
            "Tibia maximum diameter at the nutrient foramen       15\n",
            "Tibia transverse diameter at the nutrient foramen    15\n",
            "Tibia circumference at the nutrient foramen          17\n",
            "Fibula maximum length                                32\n",
            "Fibula maximum diameter at midshaft                  32\n",
            "Calcaneus maximum length                             23\n",
            "Calcaneus middle breadth                             20\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imputation: Handling Missing Values"
      ],
      "metadata": {
        "id": "1dOAgHBCKIv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import KNNImputer, IterativeImputer\n",
        "\n",
        "# Define Imputation Methods\n",
        "knn_imputer = KNNImputer(n_neighbors=3)\n",
        "iter_imputer = IterativeImputer(max_iter=1000, random_state=42)\n",
        "\n",
        "# Identify independent variables (exclude \"Pelvis Sex\")\n",
        "independent_vars = [col for col in df_mf_left_bones.columns if col != \"Pelvis Sex\"]\n",
        "\n",
        "# Create dictionary for datasets\n",
        "datasets = {\n",
        "    \"Original_L\": df_mf_left_bones.copy(),\n",
        "    \"Original_R\": df_mf_right_bones.copy(),\n",
        "    \"KNN_L\": df_mf_left_bones.copy(),\n",
        "    \"KNN_R\": df_mf_right_bones.copy(),\n",
        "    \"Iterative_L\": df_mf_left_bones.copy(),\n",
        "    \"Iterative_R\": df_mf_right_bones.copy(),\n",
        "}\n",
        "\n",
        "# Apply KNN & Iterative Imputation on the Original Datasets\n",
        "datasets[\"KNN_L\"][independent_vars] = knn_imputer.fit_transform(datasets[\"KNN_L\"][independent_vars])\n",
        "datasets[\"KNN_R\"][independent_vars] = knn_imputer.fit_transform(datasets[\"KNN_R\"][independent_vars])\n",
        "datasets[\"Iterative_L\"][independent_vars] = iter_imputer.fit_transform(datasets[\"Iterative_L\"][independent_vars])\n",
        "datasets[\"Iterative_R\"][independent_vars] = iter_imputer.fit_transform(datasets[\"Iterative_R\"][independent_vars])\n",
        "\n",
        "print(\"\\n Imputation Completed!\")\n",
        "print(f\" Available datasets: {list(datasets.keys())}\")\n",
        "print(\"\\n Missing Values After Imputation (Left - KNN):\")\n",
        "print(datasets[\"KNN_L\"].isna().sum())\n",
        "print(\"\\n Missing Values After Imputation (Right - Iterative):\")\n",
        "print(datasets[\"Iterative_R\"].isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbkOU84wCfs-",
        "outputId": "55fc8ed9-62f7-4578-a939-e41c9fb31978"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Imputation Completed!\n",
            " Available datasets: ['Original_L', 'Original_R', 'KNN_L', 'KNN_R', 'Iterative_L', 'Iterative_R']\n",
            "\n",
            " Missing Values After Imputation (Left - KNN):\n",
            "Pelvis Sex                                           0\n",
            "Clavicle maximum length                              0\n",
            "Clavicle sagittal diameter at midshaft               0\n",
            "Clavicle vertical diameter at midshaft               0\n",
            "Scapula height                                       0\n",
            "Scapula breadth                                      0\n",
            "Humerus maximum length                               0\n",
            "Humerus epicondylar breadth                          0\n",
            "Humerus vertical diameter of head                    0\n",
            "Humerus maximum diameter at midshaft                 0\n",
            "Humerus minimum diameter at midshaft                 0\n",
            "Radius maximum length                                0\n",
            "Radius sagittal diameter at midshaft                 0\n",
            "Radius transverse diameter at midshaft               0\n",
            "Ulna maximum length                                  0\n",
            "Ulna dorso-volar diameter                            0\n",
            "Ulna transverse diameter                             0\n",
            "Ulna physiological length                            0\n",
            "Ulna minimum circumference                           0\n",
            "Femur maximum heigth                                 0\n",
            "Femur bicondylar length                              0\n",
            "Femur epicondylar breadth                            0\n",
            "Femur maximum head diameter                          0\n",
            "Femur sagittal subtrochanteric diameter              0\n",
            "Femur transverse subtrochanteric diameter            0\n",
            "Femur sagittal midshaft diameter                     0\n",
            "Femur transverse midshaft diameter                   0\n",
            "Femur midshaft circumference                         0\n",
            "Tibia length                                         0\n",
            "Tibia maximum proximal epiphyseal breadth            0\n",
            "Tibia maximum distal epiphyseal breadth              0\n",
            "Tibia maximum diameter at the nutrient foramen       0\n",
            "Tibia transverse diameter at the nutrient foramen    0\n",
            "Tibia circumference at the nutrient foramen          0\n",
            "Fibula maximum length                                0\n",
            "Fibula maximum diameter at midshaft                  0\n",
            "Calcaneus maximum length                             0\n",
            "Calcaneus middle breadth                             0\n",
            "dtype: int64\n",
            "\n",
            " Missing Values After Imputation (Right - Iterative):\n",
            "Pelvis Sex                                           0\n",
            "Clavicle maximum length                              0\n",
            "Clavicle sagittal diameter at midshaft               0\n",
            "Clavicle vertical diameter at midshaft               0\n",
            "Scapula height                                       0\n",
            "Scapula breadth                                      0\n",
            "Humerus maximum length                               0\n",
            "Humerus epicondylar breadth                          0\n",
            "Humerus vertical diameter of head                    0\n",
            "Humerus maximum diameter at midshaft                 0\n",
            "Humerus minimum diameter at midshaft                 0\n",
            "Radius maximum length                                0\n",
            "Radius sagittal diameter at midshaft                 0\n",
            "Radius transverse diameter at midshaft               0\n",
            "Ulna maximum length                                  0\n",
            "Ulna dorso-volar diameter                            0\n",
            "Ulna transverse diameter                             0\n",
            "Ulna physiological length                            0\n",
            "Ulna minimum circumference                           0\n",
            "Femur maximum heigth                                 0\n",
            "Femur bicondylar length                              0\n",
            "Femur epicondylar breadth                            0\n",
            "Femur maximum head diameter                          0\n",
            "Femur sagittal subtrochanteric diameter              0\n",
            "Femur transverse subtrochanteric diameter            0\n",
            "Femur sagittal midshaft diameter                     0\n",
            "Femur transverse midshaft diameter                   0\n",
            "Femur midshaft circumference                         0\n",
            "Tibia length                                         0\n",
            "Tibia maximum proximal epiphyseal breadth            0\n",
            "Tibia maximum distal epiphyseal breadth              0\n",
            "Tibia maximum diameter at the nutrient foramen       0\n",
            "Tibia transverse diameter at the nutrient foramen    0\n",
            "Tibia circumference at the nutrient foramen          0\n",
            "Fibula maximum length                                0\n",
            "Fibula maximum diameter at midshaft                  0\n",
            "Calcaneus maximum length                             0\n",
            "Calcaneus middle breadth                             0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wilcoxon Tests for Sex-Based Differences"
      ],
      "metadata": {
        "id": "K5EpDshvKSlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Define output file paths\n",
        "wilcoxon_results_file = \"Wilcoxon_Test_Results.csv\"\n",
        "wilcoxon_results_by_bone_file = \"Wilcoxon_Test_Results_By_Bone.csv\"\n",
        "\n",
        "# Initialize results storage\n",
        "results = []\n",
        "results_by_bone = {}\n",
        "\n",
        "# Loop through all datasets and perform Wilcoxon test\n",
        "for dataset_name, df in datasets.items():\n",
        "    for var in independent_vars:\n",
        "        # Split data into Male (1) and Female (0) groups\n",
        "        males = df[df[\"Pelvis Sex\"] == 1][var].dropna()\n",
        "        females = df[df[\"Pelvis Sex\"] == 0][var].dropna()\n",
        "\n",
        "        num_males, num_females = len(males), len(females)\n",
        "\n",
        "        # Ensure both groups have enough samples for Wilcoxon test\n",
        "        if num_males > 1 and num_females > 1:\n",
        "            try:\n",
        "                stat, p_value = stats.mannwhitneyu(males, females, alternative=\"two-sided\")\n",
        "            except ValueError as e:\n",
        "                print(f\" Error for {var} in {dataset_name}: {e}\")\n",
        "                stat, p_value = None, None\n",
        "        else:\n",
        "            print(f\" Skipping {var} in {dataset_name} (Insufficient samples)\")\n",
        "            stat, p_value = None, None\n",
        "\n",
        "        # Store results in standard format (by dataset)\n",
        "        results.append({\n",
        "            \"Dataset\": dataset_name,\n",
        "            \"Variable\": var,\n",
        "            \"Wilcoxon Statistic\": stat,\n",
        "            \"p-value\": p_value,\n",
        "            \"Num Males\": num_males,\n",
        "            \"Num Females\": num_females\n",
        "        })\n",
        "\n",
        "        # Store results in grouped format (by bone)\n",
        "        if var not in results_by_bone:\n",
        "            results_by_bone[var] = []\n",
        "        results_by_bone[var].append({\n",
        "            \"Dataset\": dataset_name,\n",
        "            \"Wilcoxon Statistic\": stat,\n",
        "            \"p-value\": p_value,\n",
        "            \"Num Males\": num_males,\n",
        "            \"Num Females\": num_females\n",
        "        })\n",
        "\n",
        "# Convert standard results to DataFrame and save\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(wilcoxon_results_file, index=False)\n",
        "\n",
        "print(\"\\n Wilcoxon test results saved!\")\n",
        "print(\"\\n Wilcoxon Test Results (Sample):\")\n",
        "print(df_results.head())\n",
        "\n",
        "# Convert grouped results (by bone) to DataFrame\n",
        "grouped_results = []\n",
        "for var, data in results_by_bone.items():\n",
        "    row = {\"Variable\": var}\n",
        "    for entry in data:\n",
        "        row[f\"{entry['Dataset']} Wilcoxon Statistic\"] = entry[\"Wilcoxon Statistic\"]\n",
        "        row[f\"{entry['Dataset']} p-value\"] = entry[\"p-value\"]\n",
        "        row[f\"{entry['Dataset']} Num Males\"] = entry[\"Num Males\"]\n",
        "        row[f\"{entry['Dataset']} Num Females\"] = entry[\"Num Females\"]\n",
        "    grouped_results.append(row)\n",
        "\n",
        "df_results_by_bone = pd.DataFrame(grouped_results)\n",
        "\n",
        "# Save the grouped results\n",
        "df_results_by_bone.to_csv(wilcoxon_results_by_bone_file, index=False)\n",
        "\n",
        "print(\"\\n Wilcoxon test results grouped by bone saved!\")\n",
        "print(\"\\n Sample of Wilcoxon results grouped by bone:\")\n",
        "print(df_results_by_bone.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wntGqF-RCfqB",
        "outputId": "524e4f9d-3592-4bf5-d858-35132b430d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Skipping Scapula height in Original_R (Insufficient samples)\n",
            " Skipping Scapula breadth in Original_R (Insufficient samples)\n",
            "\n",
            " Wilcoxon test results saved!\n",
            "\n",
            " Wilcoxon Test Results (Sample):\n",
            "      Dataset                                Variable  Wilcoxon Statistic  \\\n",
            "0  Original_L                 Clavicle maximum length                64.0   \n",
            "1  Original_L  Clavicle sagittal diameter at midshaft                62.0   \n",
            "2  Original_L  Clavicle vertical diameter at midshaft                73.0   \n",
            "3  Original_L                          Scapula height                 8.0   \n",
            "4  Original_L                         Scapula breadth                 8.0   \n",
            "\n",
            "    p-value  Num Males  Num Females  \n",
            "0  0.008024          8            9  \n",
            "1  0.055711          8           10  \n",
            "2  0.003862          8           10  \n",
            "3  0.133333          4            2  \n",
            "4  0.133333          4            2  \n",
            "\n",
            " Wilcoxon test results grouped by bone saved!\n",
            "\n",
            " Sample of Wilcoxon results grouped by bone:\n",
            "                                 Variable  Original_L Wilcoxon Statistic  \\\n",
            "0                 Clavicle maximum length                           64.0   \n",
            "1  Clavicle sagittal diameter at midshaft                           62.0   \n",
            "2  Clavicle vertical diameter at midshaft                           73.0   \n",
            "3                          Scapula height                            8.0   \n",
            "4                         Scapula breadth                            8.0   \n",
            "\n",
            "   Original_L p-value  Original_L Num Males  Original_L Num Females  \\\n",
            "0            0.008024                     8                       9   \n",
            "1            0.055711                     8                      10   \n",
            "2            0.003862                     8                      10   \n",
            "3            0.133333                     4                       2   \n",
            "4            0.133333                     4                       2   \n",
            "\n",
            "   Original_R Wilcoxon Statistic  Original_R p-value  Original_R Num Males  \\\n",
            "0                           35.0            0.051282                     6   \n",
            "1                           52.0            0.006252                     7   \n",
            "2                           56.0            0.001417                     7   \n",
            "3                            NaN                 NaN                     2   \n",
            "4                            NaN                 NaN                     2   \n",
            "\n",
            "   Original_R Num Females  KNN_L Wilcoxon Statistic  ...  KNN_R Num Males  \\\n",
            "0                       7                     473.5  ...               18   \n",
            "1                       8                     399.5  ...               18   \n",
            "2                       8                     452.0  ...               18   \n",
            "3                       1                     456.0  ...               18   \n",
            "4                       1                     473.5  ...               18   \n",
            "\n",
            "   KNN_R Num Females  Iterative_L Wilcoxon Statistic  Iterative_L p-value  \\\n",
            "0                 30                           372.0         3.064066e-02   \n",
            "1                 30                           459.0         5.954637e-05   \n",
            "2                 30                           485.0         4.921854e-06   \n",
            "3                 30                           511.0         3.028569e-07   \n",
            "4                 30                           504.0         6.606453e-07   \n",
            "\n",
            "   Iterative_L Num Males  Iterative_L Num Females  \\\n",
            "0                     18                       30   \n",
            "1                     18                       30   \n",
            "2                     18                       30   \n",
            "3                     18                       30   \n",
            "4                     18                       30   \n",
            "\n",
            "   Iterative_R Wilcoxon Statistic  Iterative_R p-value  Iterative_R Num Males  \\\n",
            "0                           344.0         1.175249e-01                     18   \n",
            "1                           358.0         6.236476e-02                     18   \n",
            "2                           499.0         1.135884e-06                     18   \n",
            "3                           523.0         7.564846e-08                     18   \n",
            "4                           524.0         6.719776e-08                     18   \n",
            "\n",
            "   Iterative_R Num Females  \n",
            "0                       30  \n",
            "1                       30  \n",
            "2                       30  \n",
            "3                       30  \n",
            "4                       30  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter Wilcoxon Test Results (p > 0.04)"
      ],
      "metadata": {
        "id": "8UpLwHmxKedB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the file path (Adjust if necessary)\n",
        "file_path = \"/content/Wilcoxon_Test_Results_By_Bone.csv\"\n",
        "\n",
        "# Load the Wilcoxon test results file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Create an empty list to store filtered results\n",
        "filtered_results = []\n",
        "\n",
        "# Iterate through the DataFrame and filter for p-values > 0.04\n",
        "for index, row in df.iterrows():\n",
        "    for col in df.columns:\n",
        "        if \"p-value\" in col and row[col] > 0.04:\n",
        "            variable_name = row[\"Variable\"]\n",
        "            dataset_used = col.replace(\" p-value\", \"\")\n",
        "            filtered_results.append({\"Variable\": variable_name, \"Dataset\": dataset_used, \"p-value\": row[col]})\n",
        "\n",
        "# Convert the filtered results into a DataFrame and sort alphabetically\n",
        "df_filtered = pd.DataFrame(filtered_results).sort_values(by=[\"Variable\", \"Dataset\"])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df_filtered)\n",
        "\n",
        "# Optionally, save the filtered results to a new CSV file\n",
        "df_filtered.to_csv(\"/content/Filtered_Wilcoxon_Results.csv\", index=False)\n",
        "print(\"Filtered results saved to /content/Filtered_Wilcoxon_Results.csv\")\n"
      ],
      "metadata": {
        "id": "ipI2p1wGCfmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define and Initialize Machine Learning Models"
      ],
      "metadata": {
        "id": "UQS4Ryy6Kj09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Classifiers\n",
        "classifiers = {\n",
        "    \"XGBoost\": xgb.XGBClassifier(\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42,\n",
        "        n_estimators=200,         # more trees (default is 100)\n",
        "        learning_rate=0.05,       # slower but more precise learning\n",
        "        max_depth=4,              # slightly deeper than default (3)\n",
        "        subsample=0.9,            # helps generalization\n",
        "        colsample_bytree=0.7,     # use 90% of features per tree\n",
        "        reg_alpha=0.1,            # L1 regularization\n",
        "        reg_lambda=1.0,           # L2 regularization\n",
        "        scale_pos_weight=1.66     # to balance 30 males vs. 18 females\n",
        "    ),\n",
        "\n",
        "    \"LightGBM\": lgb.LGBMClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=4,\n",
        "        min_child_samples=10,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.1,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        verbose=-1\n",
        "    ),\n",
        "\n",
        "    \"RandomForest\": RandomForestClassifier(\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    \"LogReg\": LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "print(\"Models Defined!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPKo1NXJfKqw",
        "outputId": "54d7706b-cded-4edf-af61-dd15afebc4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models Defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up Cross-Validation Strategy"
      ],
      "metadata": {
        "id": "uXbRFHufKm8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cv_strategy(y):\n",
        "    \"\"\"\n",
        "    Returns the appropriate cross-validation strategy:\n",
        "    - LOOCV if Male/Female count < 5\n",
        "    - 5-Fold Stratified CV otherwise\n",
        "    \"\"\"\n",
        "    min_class_size = y.value_counts().min()\n",
        "\n",
        "    if min_class_size < 5:\n",
        "        return LeaveOneOut(), \"Stratified LOOCV\"\n",
        "    else:\n",
        "        return StratifiedKFold(n_splits=min(5, min_class_size), shuffle=True, random_state=42), \"5-Fold Stratified CV\"\n",
        "\n",
        "print(\" Cross-Validation Strategies Defined!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-9LOye-fRlA",
        "outputId": "d3fa7e73-1b06-434c-c7ea-8fd6fa747c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Cross-Validation Strategies Defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_classification(X, y, variable_name, model_name, dataset_name, cv_strategy, cv_type, results_df):\n",
        "    model = classifiers[model_name]\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for train_idx, test_idx in cv_strategy.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        if len(np.unique(y_train)) < 2:\n",
        "            print(f\" Skipping {variable_name} ({model_name}) - Only one class present in training data!\")\n",
        "            return results_df\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "\n",
        "        y_true.extend(y_test)\n",
        "        y_pred.extend(preds)\n",
        "\n",
        "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
        "\n",
        "    new_result = pd.DataFrame([{\n",
        "        \"Variable\": variable_name,\n",
        "        \"Model\": model_name,\n",
        "        \"Imputation\": dataset_name,\n",
        "        \"CV Strategy\": cv_type,\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Precision M\": report[\"0\"][\"precision\"],\n",
        "        \"Precision F\": report[\"1\"][\"precision\"],\n",
        "        \"Recall M\": report[\"0\"][\"recall\"],\n",
        "        \"Recall F\": report[\"1\"][\"recall\"],\n",
        "        \"F1-score M\": report[\"0\"][\"f1-score\"],\n",
        "        \"F1-score F\": report[\"1\"][\"f1-score\"],\n",
        "        \"Sample size M\": report[\"0\"][\"support\"],\n",
        "        \"Sample size F\": report[\"1\"][\"support\"]\n",
        "    }])\n",
        "\n",
        "    results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
        "\n",
        "    print(f\" Recorded results for {variable_name} using {model_name} ({cv_type})\")\n",
        "    return results_df\n",
        "\n"
      ],
      "metadata": {
        "id": "M3NKYR3gfW5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Evaluate Models for Individual Bone Measurements\n"
      ],
      "metadata": {
        "id": "rQr-49lnKvrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Define Folder for Plots\n",
        "plots_folder = \"/content/drive/MyDrive/Dion-results/Overfitting_Plots\"\n",
        "os.makedirs(plots_folder, exist_ok=True)\n",
        "\n",
        "# Generate Timestamp for File Naming\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "results_file = f\"/content/drive/MyDrive/Dion-results/Sex_Classification_{timestamp}.csv\"\n",
        "\n",
        "# Initialize Results DataFrame\n",
        "results_df = pd.DataFrame(columns=[\"Variable\", \"Model\", \"Imputation\", \"CV Strategy\", \"Accuracy\",\n",
        "                                   \"Precision M\", \"Precision F\", \"Recall M\", \"Recall F\",\n",
        "                                   \"F1-score M\", \"F1-score F\", \"Sample size M\", \"Sample size F\"])\n",
        "\n",
        "# Debug: Ensure datasets exist\n",
        "if not datasets:\n",
        "    print(\" ERROR: 'datasets' dictionary is empty! Check dataset loading.\")\n",
        "\n",
        "# Loop Over Each Dataset\n",
        "for dataset_name, df in datasets.items():\n",
        "    y = df[\"Pelvis Sex\"]\n",
        "\n",
        "    for variable in df.drop(columns=[\"Pelvis Sex\"]).columns:\n",
        "        X = df[[variable]]\n",
        "        cv_strategy, cv_type = get_cv_strategy(y)\n",
        "\n",
        "        for model_name in classifiers.keys():\n",
        "            # Boosting classifiers run on all datasets, RF & LogReg only on KNN & Iterative\n",
        "            if model_name in [\"XGBoost\", \"LightGBM\"] or dataset_name in [\"KNN_L\", \"KNN_R\", \"Iterative_L\", \"Iterative_R\"]:\n",
        "\n",
        "                # Debug: Ensure the function is called\n",
        "                print(f\" Running classification for: {variable} ({model_name}, {dataset_name})\")\n",
        "\n",
        "                # Run classification and collect results\n",
        "                results_df = run_classification(X, y, variable, model_name, dataset_name, cv_strategy, cv_type, results_df)\n",
        "\n",
        "                # Debug: Check if results_df is being updated\n",
        "                if results_df.empty:\n",
        "                    print(f\" ERROR: results_df is empty after processing {variable} ({model_name}, {dataset_name})\")\n",
        "\n",
        "                # Generate overfitting plots\n",
        "                train_scores, test_scores = [], []\n",
        "\n",
        "                for train_idx, test_idx in cv_strategy.split(X, y):\n",
        "                    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "                    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "                    if len(np.unique(y_train)) < 2:\n",
        "                        continue  # Skip iterations with only one class in training data\n",
        "\n",
        "                    model = classifiers[model_name]\n",
        "                    model.fit(X_train, y_train)\n",
        "\n",
        "                    train_scores.append(model.score(X_train, y_train))\n",
        "                    test_scores.append(model.score(X_test, y_test))\n",
        "\n",
        "                # Plot Training vs. Test Scores\n",
        "                plt.figure(figsize=(8, 6))\n",
        "                plt.plot(range(len(train_scores)), train_scores, label=\"Train Score\", marker=\"o\", linestyle=\"-\")\n",
        "                plt.plot(range(len(test_scores)), test_scores, label=\"Test Score\", marker=\"o\", linestyle=\"--\")\n",
        "                plt.xlabel(\"Fold Number\")\n",
        "                plt.ylabel(\"Accuracy\")\n",
        "                plt.title(f\"Overfitting Analysis - {variable} ({model_name}, {dataset_name})\")\n",
        "                plt.legend()\n",
        "                plt.grid()\n",
        "\n",
        "                # Save Plot\n",
        "                plot_filename = f\"{plots_folder}/{variable}_{model_name}_{dataset_name}.png\"\n",
        "                plt.savefig(plot_filename)\n",
        "                plt.close()\n",
        "\n",
        "# Debug: Ensure DataFrame is not empty before saving\n",
        "if results_df.empty:\n",
        "    print(\" ERROR: results_df is empty! No results to save.\")\n",
        "else:\n",
        "    # Save Results\n",
        "    results_df.to_csv(results_file, index=False)\n",
        "    print(f\" Individual Variable Classification Results saved to {results_file}!\")\n",
        "\n",
        "# Debug: Verify File Exists\n",
        "if os.path.exists(results_file):\n",
        "    print(f\" CSV file successfully created at: {results_file}\")\n",
        "else:\n",
        "    print(\" ERROR: CSV file was not created!\")\n"
      ],
      "metadata": {
        "id": "lNWc1s2whwf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Evaluate Models for Bone Groups"
      ],
      "metadata": {
        "id": "UstztkLFK3r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Define Bone Groups\n",
        "bone_groups = {\n",
        "    \"Clavicle\": [\"Clavicle maximum length\", \"Clavicle sagittal diameter at midshaft\", \"Clavicle vertical diameter at midshaft\"],\n",
        "    \"Scapula\": [\"Scapula height\", \"Scapula breadth\"],\n",
        "    \"Humerus\": [\"Humerus maximum length\", \"Humerus epicondylar breadth\", \"Humerus vertical diameter of head\",\n",
        "                \"Humerus maximum diameter at midshaft\", \"Humerus minimum diameter at midshaft\"],\n",
        "    \"Radius\": [\"Radius maximum length\", \"Radius sagittal diameter at midshaft\", \"Radius transverse diameter at midshaft\"],\n",
        "    \"Ulna\": [\"Ulna maximum length\", \"Ulna dorso-volar diameter\", \"Ulna transverse diameter\",\n",
        "             \"Ulna physiological length\", \"Ulna minimum circumference\"],\n",
        "    \"Femur\": [\"Femur maximum heigth\", \"Femur bicondylar length\", \"Femur epicondylar breadth\",\n",
        "              \"Femur maximum head diameter\", \"Femur sagittal subtrochanteric diameter\",\n",
        "              \"Femur transverse subtrochanteric diameter\", \"Femur sagittal midshaft diameter\",\n",
        "              \"Femur transverse midshaft diameter\", \"Femur midshaft circumference\"],\n",
        "    \"Tibia\": [\"Tibia length\", \"Tibia maximum proximal epiphyseal breadth\", \"Tibia maximum distal epiphyseal breadth\",\n",
        "              \"Tibia maximum diameter at the nutrient foramen\", \"Tibia transverse diameter at the nutrient foramen\",\n",
        "              \"Tibia circumference at the nutrient foramen\"],\n",
        "    \"Fibula\": [\"Fibula maximum length\", \"Fibula maximum diameter at midshaft\"],\n",
        "    \"Calcaneus\": [\"Calcaneus maximum length\", \"Calcaneus middle breadth\"]\n",
        "}\n",
        "\n",
        "# Define Folder for Bone Group Plots\n",
        "group_plots_folder = \"/content/drive/MyDrive/Dion-results/Overfitting_Plots_BoneGroups\"\n",
        "os.makedirs(group_plots_folder, exist_ok=True)\n",
        "\n",
        "# Generate Timestamp for File Naming\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "group_results_file = f\"/content/drive/MyDrive/Dion-results/Bone_Groups_{timestamp}.csv\"\n",
        "\n",
        "# Initialize Results DataFrame\n",
        "group_results_df = pd.DataFrame(columns=[\"Variable\", \"Model\", \"Imputation\", \"CV Strategy\", \"Accuracy\",\n",
        "                                         \"Precision M\", \"Precision F\", \"Recall M\", \"Recall F\",\n",
        "                                         \"F1-score M\", \"F1-score F\", \"Sample size M\", \"Sample size F\"])\n",
        "\n",
        "# Loop Over Each Dataset\n",
        "for dataset_name, df in datasets.items():\n",
        "    y = df[\"Pelvis Sex\"]\n",
        "\n",
        "    for group_name, variables in bone_groups.items():\n",
        "        # Ensure only available variables are used\n",
        "        valid_vars = [var for var in variables if var in df.columns]\n",
        "        if not valid_vars:\n",
        "            print(f\" Skipping {group_name} ({dataset_name}) - No valid data!\")\n",
        "            continue\n",
        "\n",
        "        X_group = df[valid_vars]\n",
        "        cv_strategy, cv_type = get_cv_strategy(y)\n",
        "\n",
        "        for model_name in classifiers.keys():\n",
        "            if model_name in [\"XGBoost\", \"LightGBM\"]:\n",
        "                print(f\" Running {model_name} on {group_name} ({dataset_name}) - Keeping NaNs\")\n",
        "                X_used = X_group\n",
        "                y_used = y\n",
        "            else:\n",
        "                if dataset_name not in [\"KNN_L\", \"KNN_R\", \"Iterative_L\", \"Iterative_R\"]:\n",
        "                    continue\n",
        "                X_used = X_group.dropna()\n",
        "                y_used = y.loc[X_used.index]\n",
        "\n",
        "                if len(X_used) == 0:\n",
        "                    print(f\" Skipping {group_name} ({dataset_name}) - No valid samples after dropping NaNs!\")\n",
        "                    continue\n",
        "\n",
        "                print(f\" Running {model_name} on {group_name} ({dataset_name}) - Dropping NaNs\")\n",
        "\n",
        "            # Run classification\n",
        "            group_results_df = run_classification(X_used, y_used, group_name, model_name, dataset_name,\n",
        "                                                  cv_strategy, cv_type, group_results_df)\n",
        "\n",
        "            # Overfitting Analysis\n",
        "            train_scores, test_scores = [], []\n",
        "\n",
        "            for train_idx, test_idx in cv_strategy.split(X_used, y_used):\n",
        "                X_train, X_test = X_used.iloc[train_idx], X_used.iloc[test_idx]\n",
        "                y_train, y_test = y_used.iloc[train_idx], y_used.iloc[test_idx]\n",
        "\n",
        "                if len(np.unique(y_train)) < 2:\n",
        "                    continue  # Skip if only one class present in fold\n",
        "\n",
        "                model = classifiers[model_name]\n",
        "                model.fit(X_train, y_train)\n",
        "                train_scores.append(model.score(X_train, y_train))\n",
        "                test_scores.append(model.score(X_test, y_test))\n",
        "\n",
        "            # Plot Train vs Test Accuracy\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            plt.plot(range(len(train_scores)), train_scores, label=\"Train Score\", marker=\"o\", linestyle=\"-\")\n",
        "            plt.plot(range(len(test_scores)), test_scores, label=\"Test Score\", marker=\"o\", linestyle=\"--\")\n",
        "            plt.xlabel(\"Fold Number\")\n",
        "            plt.ylabel(\"Accuracy\")\n",
        "            plt.title(f\"Overfitting Analysis - {group_name} ({model_name}, {dataset_name})\")\n",
        "            plt.legend()\n",
        "            plt.grid()\n",
        "\n",
        "            plot_filename = f\"{group_plots_folder}/{group_name}_{model_name}_{dataset_name}.png\"\n",
        "            plt.savefig(plot_filename)\n",
        "            plt.close()\n",
        "\n",
        "# Save Results\n",
        "group_results_df.to_csv(group_results_file, index=False)\n",
        "print(f\" Bone Group Classification Results saved to {group_results_file}!\")\n",
        "print(f\" Overfitting Analysis Plots for Bone Groups saved in {group_plots_folder}!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCd1FpivIPC3",
        "outputId": "0d5019bf-cfc0-4e01-8ccd-a15b152c552e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Running XGBoost on Clavicle (Original_L) - Keeping NaNs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-96e35fdcd978>:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_df = pd.concat([results_df, new_result], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Recorded results for Clavicle using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Clavicle (Original_L) - Keeping NaNs\n",
            " Recorded results for Clavicle using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Scapula (Original_L) - Keeping NaNs\n",
            " Recorded results for Scapula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Scapula (Original_L) - Keeping NaNs\n",
            " Recorded results for Scapula using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Humerus (Original_L) - Keeping NaNs\n",
            " Recorded results for Humerus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Humerus (Original_L) - Keeping NaNs\n",
            " Recorded results for Humerus using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Radius (Original_L) - Keeping NaNs\n",
            " Recorded results for Radius using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Radius (Original_L) - Keeping NaNs\n",
            " Recorded results for Radius using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Ulna (Original_L) - Keeping NaNs\n",
            " Recorded results for Ulna using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Ulna (Original_L) - Keeping NaNs\n",
            " Recorded results for Ulna using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Femur (Original_L) - Keeping NaNs\n",
            " Recorded results for Femur using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Femur (Original_L) - Keeping NaNs\n",
            " Recorded results for Femur using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Tibia (Original_L) - Keeping NaNs\n",
            " Recorded results for Tibia using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Tibia (Original_L) - Keeping NaNs\n",
            " Recorded results for Tibia using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Fibula (Original_L) - Keeping NaNs\n",
            " Recorded results for Fibula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Fibula (Original_L) - Keeping NaNs\n",
            " Recorded results for Fibula using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Calcaneus (Original_L) - Keeping NaNs\n",
            " Recorded results for Calcaneus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Calcaneus (Original_L) - Keeping NaNs\n",
            " Recorded results for Calcaneus using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Clavicle (Original_R) - Keeping NaNs\n",
            " Recorded results for Clavicle using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Clavicle (Original_R) - Keeping NaNs\n",
            " Recorded results for Clavicle using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Scapula (Original_R) - Keeping NaNs\n",
            " Recorded results for Scapula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Scapula (Original_R) - Keeping NaNs\n",
            " Recorded results for Scapula using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Humerus (Original_R) - Keeping NaNs\n",
            " Recorded results for Humerus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Humerus (Original_R) - Keeping NaNs\n",
            " Recorded results for Humerus using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Radius (Original_R) - Keeping NaNs\n",
            " Recorded results for Radius using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Radius (Original_R) - Keeping NaNs\n",
            " Recorded results for Radius using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Ulna (Original_R) - Keeping NaNs\n",
            " Recorded results for Ulna using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Ulna (Original_R) - Keeping NaNs\n",
            " Recorded results for Ulna using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Femur (Original_R) - Keeping NaNs\n",
            " Recorded results for Femur using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Femur (Original_R) - Keeping NaNs\n",
            " Recorded results for Femur using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Tibia (Original_R) - Keeping NaNs\n",
            " Recorded results for Tibia using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Tibia (Original_R) - Keeping NaNs\n",
            " Recorded results for Tibia using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Fibula (Original_R) - Keeping NaNs\n",
            " Recorded results for Fibula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Fibula (Original_R) - Keeping NaNs\n",
            " Recorded results for Fibula using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Calcaneus (Original_R) - Keeping NaNs\n",
            " Recorded results for Calcaneus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Calcaneus (Original_R) - Keeping NaNs\n",
            " Recorded results for Calcaneus using LightGBM (5-Fold Stratified CV)\n",
            " Running XGBoost on Clavicle (KNN_L) - Keeping NaNs\n",
            " Recorded results for Clavicle using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Clavicle (KNN_L) - Keeping NaNs\n",
            " Recorded results for Clavicle using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Clavicle (KNN_L) - Dropping NaNs\n",
            " Recorded results for Clavicle using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Clavicle (KNN_L) - Dropping NaNs\n",
            " Recorded results for Clavicle using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Scapula (KNN_L) - Keeping NaNs\n",
            " Recorded results for Scapula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Scapula (KNN_L) - Keeping NaNs\n",
            " Recorded results for Scapula using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Scapula (KNN_L) - Dropping NaNs\n",
            " Recorded results for Scapula using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Scapula (KNN_L) - Dropping NaNs\n",
            " Recorded results for Scapula using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Humerus (KNN_L) - Keeping NaNs\n",
            " Recorded results for Humerus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Humerus (KNN_L) - Keeping NaNs\n",
            " Recorded results for Humerus using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Humerus (KNN_L) - Dropping NaNs\n",
            " Recorded results for Humerus using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Humerus (KNN_L) - Dropping NaNs\n",
            " Recorded results for Humerus using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Radius (KNN_L) - Keeping NaNs\n",
            " Recorded results for Radius using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Radius (KNN_L) - Keeping NaNs\n",
            " Recorded results for Radius using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Radius (KNN_L) - Dropping NaNs\n",
            " Recorded results for Radius using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Radius (KNN_L) - Dropping NaNs\n",
            " Recorded results for Radius using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Ulna (KNN_L) - Keeping NaNs\n",
            " Recorded results for Ulna using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Ulna (KNN_L) - Keeping NaNs\n",
            " Recorded results for Ulna using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Ulna (KNN_L) - Dropping NaNs\n",
            " Recorded results for Ulna using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Ulna (KNN_L) - Dropping NaNs\n",
            " Recorded results for Ulna using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Femur (KNN_L) - Keeping NaNs\n",
            " Recorded results for Femur using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Femur (KNN_L) - Keeping NaNs\n",
            " Recorded results for Femur using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Femur (KNN_L) - Dropping NaNs\n",
            " Recorded results for Femur using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Femur (KNN_L) - Dropping NaNs\n",
            " Recorded results for Femur using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Tibia (KNN_L) - Keeping NaNs\n",
            " Recorded results for Tibia using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Tibia (KNN_L) - Keeping NaNs\n",
            " Recorded results for Tibia using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Tibia (KNN_L) - Dropping NaNs\n",
            " Recorded results for Tibia using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Tibia (KNN_L) - Dropping NaNs\n",
            " Recorded results for Tibia using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Fibula (KNN_L) - Keeping NaNs\n",
            " Recorded results for Fibula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Fibula (KNN_L) - Keeping NaNs\n",
            " Recorded results for Fibula using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Fibula (KNN_L) - Dropping NaNs\n",
            " Recorded results for Fibula using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Fibula (KNN_L) - Dropping NaNs\n",
            " Recorded results for Fibula using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Calcaneus (KNN_L) - Keeping NaNs\n",
            " Recorded results for Calcaneus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Calcaneus (KNN_L) - Keeping NaNs\n",
            " Recorded results for Calcaneus using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Calcaneus (KNN_L) - Dropping NaNs\n",
            " Recorded results for Calcaneus using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Calcaneus (KNN_L) - Dropping NaNs\n",
            " Recorded results for Calcaneus using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Clavicle (KNN_R) - Keeping NaNs\n",
            " Recorded results for Clavicle using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Clavicle (KNN_R) - Keeping NaNs\n",
            " Recorded results for Clavicle using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Clavicle (KNN_R) - Dropping NaNs\n",
            " Recorded results for Clavicle using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Clavicle (KNN_R) - Dropping NaNs\n",
            " Recorded results for Clavicle using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Scapula (KNN_R) - Keeping NaNs\n",
            " Recorded results for Scapula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Scapula (KNN_R) - Keeping NaNs\n",
            " Recorded results for Scapula using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Scapula (KNN_R) - Dropping NaNs\n",
            " Recorded results for Scapula using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Scapula (KNN_R) - Dropping NaNs\n",
            " Recorded results for Scapula using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Humerus (KNN_R) - Keeping NaNs\n",
            " Recorded results for Humerus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Humerus (KNN_R) - Keeping NaNs\n",
            " Recorded results for Humerus using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Humerus (KNN_R) - Dropping NaNs\n",
            " Recorded results for Humerus using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Humerus (KNN_R) - Dropping NaNs\n",
            " Recorded results for Humerus using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Radius (KNN_R) - Keeping NaNs\n",
            " Recorded results for Radius using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Radius (KNN_R) - Keeping NaNs\n",
            " Recorded results for Radius using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Radius (KNN_R) - Dropping NaNs\n",
            " Recorded results for Radius using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Radius (KNN_R) - Dropping NaNs\n",
            " Recorded results for Radius using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Ulna (KNN_R) - Keeping NaNs\n",
            " Recorded results for Ulna using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Ulna (KNN_R) - Keeping NaNs\n",
            " Recorded results for Ulna using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Ulna (KNN_R) - Dropping NaNs\n",
            " Recorded results for Ulna using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Ulna (KNN_R) - Dropping NaNs\n",
            " Recorded results for Ulna using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Femur (KNN_R) - Keeping NaNs\n",
            " Recorded results for Femur using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Femur (KNN_R) - Keeping NaNs\n",
            " Recorded results for Femur using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Femur (KNN_R) - Dropping NaNs\n",
            " Recorded results for Femur using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Femur (KNN_R) - Dropping NaNs\n",
            " Recorded results for Femur using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Tibia (KNN_R) - Keeping NaNs\n",
            " Recorded results for Tibia using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Tibia (KNN_R) - Keeping NaNs\n",
            " Recorded results for Tibia using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Tibia (KNN_R) - Dropping NaNs\n",
            " Recorded results for Tibia using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Tibia (KNN_R) - Dropping NaNs\n",
            " Recorded results for Tibia using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Fibula (KNN_R) - Keeping NaNs\n",
            " Recorded results for Fibula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Fibula (KNN_R) - Keeping NaNs\n",
            " Recorded results for Fibula using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Fibula (KNN_R) - Dropping NaNs\n",
            " Recorded results for Fibula using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Fibula (KNN_R) - Dropping NaNs\n",
            " Recorded results for Fibula using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Calcaneus (KNN_R) - Keeping NaNs\n",
            " Recorded results for Calcaneus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Calcaneus (KNN_R) - Keeping NaNs\n",
            " Recorded results for Calcaneus using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Calcaneus (KNN_R) - Dropping NaNs\n",
            " Recorded results for Calcaneus using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Calcaneus (KNN_R) - Dropping NaNs\n",
            " Recorded results for Calcaneus using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Clavicle (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Clavicle using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Clavicle (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Clavicle using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Clavicle (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Clavicle using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Clavicle (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Clavicle using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Scapula (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Scapula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Scapula (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Scapula using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Scapula (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Scapula using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Scapula (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Scapula using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Humerus (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Humerus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Humerus (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Humerus using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Humerus (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Humerus using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Humerus (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Humerus using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Radius (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Radius using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Radius (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Radius using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Radius (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Radius using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Radius (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Radius using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Ulna (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Ulna using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Ulna (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Ulna using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Ulna (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Ulna using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Ulna (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Ulna using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Femur (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Femur using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Femur (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Femur using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Femur (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Femur using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Femur (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Femur using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Tibia (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Tibia using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Tibia (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Tibia using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Tibia (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Tibia using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Tibia (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Tibia using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Fibula (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Fibula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Fibula (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Fibula using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Fibula (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Fibula using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Fibula (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Fibula using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Calcaneus (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Calcaneus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Calcaneus (Iterative_L) - Keeping NaNs\n",
            " Recorded results for Calcaneus using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Calcaneus (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Calcaneus using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Calcaneus (Iterative_L) - Dropping NaNs\n",
            " Recorded results for Calcaneus using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Clavicle (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Clavicle using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Clavicle (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Clavicle using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Clavicle (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Clavicle using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Clavicle (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Clavicle using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Scapula (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Scapula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Scapula (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Scapula using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Scapula (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Scapula using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Scapula (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Scapula using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Humerus (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Humerus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Humerus (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Humerus using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Humerus (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Humerus using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Humerus (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Humerus using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Radius (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Radius using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Radius (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Radius using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Radius (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Radius using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Radius (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Radius using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Ulna (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Ulna using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Ulna (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Ulna using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Ulna (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Ulna using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Ulna (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Ulna using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Femur (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Femur using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Femur (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Femur using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Femur (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Femur using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Femur (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Femur using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Tibia (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Tibia using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Tibia (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Tibia using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Tibia (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Tibia using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Tibia (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Tibia using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Fibula (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Fibula using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Fibula (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Fibula using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Fibula (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Fibula using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Fibula (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Fibula using LogReg (5-Fold Stratified CV)\n",
            " Running XGBoost on Calcaneus (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Calcaneus using XGBoost (5-Fold Stratified CV)\n",
            " Running LightGBM on Calcaneus (Iterative_R) - Keeping NaNs\n",
            " Recorded results for Calcaneus using LightGBM (5-Fold Stratified CV)\n",
            " Running RandomForest on Calcaneus (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Calcaneus using RandomForest (5-Fold Stratified CV)\n",
            " Running LogReg on Calcaneus (Iterative_R) - Dropping NaNs\n",
            " Recorded results for Calcaneus using LogReg (5-Fold Stratified CV)\n",
            "Bone Group Classification Results saved to /content/drive/MyDrive/Dion-results/Bone_Groups_20250531_165627.csv!\n",
            "Overfitting and ROC Plots (Train + Test) saved in /content/drive/MyDrive/Dion-results/Overfitting_Plots_BoneGroups!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify the Best Models for Individual Variables"
      ],
      "metadata": {
        "id": "IFwOgd2eK98X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define file path for Sex Classification results\n",
        "\n",
        "# Copy the output file from above\n",
        "sex_classification_file = \"/content/drive/MyDrive/Dion-results/Sex_Classification_20250327_125312.csv\"\n",
        "\n",
        "# Load the CSV file\n",
        "df_sex = pd.read_csv(sex_classification_file)\n",
        "\n",
        "# Extract unique variable names (remove L/R labels)\n",
        "df_sex[\"Base Variable\"] = df_sex[\"Variable\"]\n",
        "\n",
        "# Identify the best classifier for each variable (Left and Right separately)\n",
        "top_models = []\n",
        "for var in df_sex[\"Base Variable\"].unique():\n",
        "    df_var = df_sex[df_sex[\"Base Variable\"] == var]\n",
        "\n",
        "    # Best model for Left (L)\n",
        "    df_L = df_var[df_var[\"Imputation\"].str.contains(\"_L\")]\n",
        "    if not df_L.empty:\n",
        "        top_L = df_L.loc[df_L[\"Accuracy\"].idxmax()]\n",
        "        top_models.append(top_L)\n",
        "\n",
        "    # Best model for Right (R)\n",
        "    df_R = df_var[df_var[\"Imputation\"].str.contains(\"_R\")]\n",
        "    if not df_R.empty:\n",
        "        top_R = df_R.loc[df_R[\"Accuracy\"].idxmax()]\n",
        "        top_models.append(top_R)\n",
        "\n",
        "# Create DataFrame with the top classifiers\n",
        "df_top_sex = pd.DataFrame(top_models)\n",
        "\n",
        "# Sort to keep Left & Right variables together\n",
        "df_top_sex = df_top_sex.sort_values(by=[\"Base Variable\", \"Imputation\"])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df_top_sex = df_top_sex.drop(columns=[\"Base Variable\"])\n",
        "\n",
        "# Format floating-point numbers to two decimal places\n",
        "float_cols = [\"Accuracy\", \"Precision M\", \"Precision F\", \"Recall M\", \"Recall F\", \"F1-score M\", \"F1-score F\"]\n",
        "df_top_sex[float_cols] = df_top_sex[float_cols].applymap(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "# Display results\n",
        "print(\" Top classifiers for individual variables:\")\n",
        "print(df_top_sex)\n",
        "\n",
        "# Save results\n",
        "df_top_sex.to_csv(\"/content/Top_Individual_Variables.csv\", index=False)\n",
        "\n",
        "print(\" Processed and saved top classifiers for individual variables.\")\n",
        "\n",
        "# Generate LaTeX table\n",
        "latex_individual = df_top_sex.to_latex(index=False, column_format=\"lccccccccc\",\n",
        "                                       caption=\"Top Classifiers for Individual Variables (Left & Right)\",\n",
        "                                       label=\"tab:top_individual\")\n",
        "\n",
        "# Save LaTeX table\n",
        "with open(\"/content/Top_Individual_Variables.tex\", \"w\") as f:\n",
        "    f.write(latex_individual)\n",
        "\n",
        "print(\" LaTeX table generated! Download 'Top_Individual_Variables.tex' and insert into Overleaf.\")\n"
      ],
      "metadata": {
        "id": "6siryIThOm9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify the Best Models for Bone Groups"
      ],
      "metadata": {
        "id": "N1RNhlfVLCPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define file path for Bone Group Classification results\n",
        "\n",
        "# Copy output file from above\n",
        "bone_groups_file = \"/content/drive/MyDrive/Dion-results/Bone_Groups_20250327_130942.csv\"\n",
        "\n",
        "# Load the CSV file\n",
        "df_bone = pd.read_csv(bone_groups_file)\n",
        "\n",
        "# Extract unique bone group names\n",
        "df_bone[\"Base Variable\"] = df_bone[\"Variable\"]\n",
        "\n",
        "# Identify the best classifier for each bone group (Left and Right separately)\n",
        "top_models = []\n",
        "for var in df_bone[\"Base Variable\"].unique():\n",
        "    df_var = df_bone[df_bone[\"Base Variable\"] == var]\n",
        "\n",
        "    # Best model for Left (L)\n",
        "    df_L = df_var[df_var[\"Imputation\"].str.contains(\"_L\")]\n",
        "    if not df_L.empty:\n",
        "        top_L = df_L.loc[df_L[\"Accuracy\"].idxmax()]\n",
        "        top_models.append(top_L)\n",
        "\n",
        "    # Best model for Right (R)\n",
        "    df_R = df_var[df_var[\"Imputation\"].str.contains(\"_R\")]\n",
        "    if not df_R.empty:\n",
        "        top_R = df_R.loc[df_R[\"Accuracy\"].idxmax()]\n",
        "        top_models.append(top_R)\n",
        "\n",
        "# Create DataFrame with the top classifiers\n",
        "df_top_bone = pd.DataFrame(top_models)\n",
        "\n",
        "# Sort to keep Left & Right bone groups together\n",
        "df_top_bone = df_top_bone.sort_values(by=[\"Base Variable\", \"Imputation\"])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df_top_bone = df_top_bone.drop(columns=[\"Base Variable\"])\n",
        "\n",
        "# Format floating-point numbers to two decimal places\n",
        "df_top_bone[float_cols] = df_top_bone[float_cols].applymap(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "# Display results\n",
        "print(\" Top classifiers for bone groups:\")\n",
        "print(df_top_bone)\n",
        "\n",
        "# Save results\n",
        "df_top_bone.to_csv(\"/content/Top_Bone_Groups.csv\", index=False)\n",
        "\n",
        "print(\" Processed and saved top classifiers for bone groups.\")\n",
        "\n",
        "# Generate LaTeX table\n",
        "latex_bone = df_top_bone.to_latex(index=False, column_format=\"lccccccccc\",\n",
        "                                  caption=\"Top Classifiers for Bone Groups (Left & Right)\",\n",
        "                                  label=\"tab:top_bone_groups\")\n",
        "\n",
        "# Save LaTeX table\n",
        "with open(\"/content/Top_Bone_Groups.tex\", \"w\") as f:\n",
        "    f.write(latex_bone)\n",
        "\n",
        "print(\" LaTeX table generated! Download 'Top_Bone_Groups.tex' and insert into Overleaf.\")\n"
      ],
      "metadata": {
        "id": "9R67uHxnjtTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Logistic Regression Models on Bone Groups and Export to Text"
      ],
      "metadata": {
        "id": "wbX8fvCP5v-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Export Logistic Regression Models for Bone Groups\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Output folder\n",
        "logreg_model_folder = \"/content/drive/MyDrive/Dion-results/Exported_LogReg_BoneGroups\"\n",
        "os.makedirs(logreg_model_folder, exist_ok=True)\n",
        "\n",
        "# Use only imputed datasets\n",
        "datasets_to_use = [\"KNN_L\", \"KNN_R\", \"Iterative_L\", \"Iterative_R\"]\n",
        "\n",
        "# Bone group definitions\n",
        "bone_groups = {\n",
        "    \"Clavicle\": [\"Clavicle maximum length\", \"Clavicle sagittal diameter at midshaft\", \"Clavicle vertical diameter at midshaft\"],\n",
        "    \"Scapula\": [\"Scapula height\", \"Scapula breadth\"],\n",
        "    \"Humerus\": [\"Humerus maximum length\", \"Humerus epicondylar breadth\", \"Humerus vertical diameter of head\",\n",
        "                \"Humerus maximum diameter at midshaft\", \"Humerus minimum diameter at midshaft\"],\n",
        "    \"Radius\": [\"Radius maximum length\", \"Radius sagittal diameter at midshaft\", \"Radius transverse diameter at midshaft\"],\n",
        "    \"Ulna\": [\"Ulna maximum length\", \"Ulna dorso-volar diameter\", \"Ulna transverse diameter\",\n",
        "             \"Ulna physiological length\", \"Ulna minimum circumference\"],\n",
        "    \"Femur\": [\"Femur maximum heigth\", \"Femur bicondylar length\", \"Femur epicondylar breadth\",\n",
        "              \"Femur maximum head diameter\", \"Femur sagittal subtrochanteric diameter\",\n",
        "              \"Femur transverse subtrochanteric diameter\", \"Femur sagittal midshaft diameter\",\n",
        "              \"Femur transverse midshaft diameter\", \"Femur midshaft circumference\"],\n",
        "    \"Tibia\": [\"Tibia length\", \"Tibia maximum proximal epiphyseal breadth\", \"Tibia maximum distal epiphyseal breadth\",\n",
        "              \"Tibia maximum diameter at the nutrient foramen\", \"Tibia transverse diameter at the nutrient foramen\",\n",
        "              \"Tibia circumference at the nutrient foramen\"],\n",
        "    \"Fibula\": [\"Fibula maximum length\", \"Fibula maximum diameter at midshaft\"],\n",
        "    \"Calcaneus\": [\"Calcaneus maximum length\", \"Calcaneus middle breadth\"]\n",
        "}\n",
        "\n",
        "# Loop through datasets and bone groups\n",
        "for dataset_name, df in datasets.items():\n",
        "    if dataset_name not in datasets_to_use:\n",
        "        continue\n",
        "\n",
        "    y = df[\"Pelvis Sex\"]\n",
        "\n",
        "    for group_name, features in bone_groups.items():\n",
        "        valid_features = [f for f in features if f in df.columns]\n",
        "        if not valid_features:\n",
        "            print(f\"Skipping {group_name} ({dataset_name}) - No valid features\")\n",
        "            continue\n",
        "\n",
        "        X = df[valid_features].dropna()\n",
        "        y_subset = y.loc[X.index]\n",
        "\n",
        "        if len(X) < 2 or len(np.unique(y_subset)) < 2:\n",
        "            print(f\"Skipping {group_name} ({dataset_name}) - Not enough data or only one class\")\n",
        "            continue\n",
        "\n",
        "        # Train on all available data\n",
        "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "        model.fit(X, y_subset)\n",
        "\n",
        "        intercept = model.intercept_[0]\n",
        "        coefs = model.coef_[0]\n",
        "\n",
        "        file_path = os.path.join(logreg_model_folder, f\"LogisticRegression_{group_name}_{dataset_name}.txt\")\n",
        "        with open(file_path, \"w\") as f:\n",
        "            f.write(f\"Logistic Regression Model for {group_name} ({dataset_name})\\n\\n\")\n",
        "            f.write(\"Binary classification: 0 = Female, 1 = Male\\n\")\n",
        "            f.write(f\"Samples used: {len(X)}\\n\\n\")\n",
        "\n",
        "            f.write(f\"Intercept: {intercept:.6f}\\n\\n\")\n",
        "            f.write(\"Coefficients:\\n\")\n",
        "            for feature, coef in zip(valid_features, coefs):\n",
        "                f.write(f\"  {feature}: {coef:.6f}\\n\")\n",
        "\n",
        "            f.write(\"\\nFeature Order:\\n\")\n",
        "            f.write(\", \".join(valid_features) + \"\\n\\n\")\n",
        "\n",
        "            f.write(\"Classification Rule:\\n\")\n",
        "            f.write(\"Compute the score using your measurements:\\n\\n\")\n",
        "            formula = f\"{intercept:.3f} + \" + \" + \".join([f\"{coef:.3f} × {feat}\" for coef, feat in zip(coefs, valid_features)])\n",
        "            f.write(f\"  Score = {formula}\\n\\n\")\n",
        "            f.write(\"Then apply the rule:\\n\")\n",
        "            f.write(\"  If Score > 0 → Classify as Male\\n\")\n",
        "            f.write(\"  If Score ≤ 0 → Classify as Female\\n\\n\")\n",
        "\n",
        "            f.write(\"Example (replace values with your measurements):\\n\")\n",
        "            example = f\"{intercept:.3f}\"\n",
        "            for coef, feat in zip(coefs, valid_features):\n",
        "                example += f\" + ({coef:.3f} × [your {feat}])\"\n",
        "            f.write(f\"  Score = {example}\\n\")\n",
        "\n",
        "        print(f\"Exported: {file_path}\")\n"
      ],
      "metadata": {
        "id": "keYoDHZrvTC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Export Boosted Models for Bone Groups (as Pickle Files)"
      ],
      "metadata": {
        "id": "_0LnSYScEoAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Export XGBoost, LightGBM, and RandomForest Models for Bone Groups\n",
        "\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Output folder\n",
        "boosted_model_folder = \"/content/drive/MyDrive/Dion-results/Exported_Pickled_BoostedModels\"\n",
        "os.makedirs(boosted_model_folder, exist_ok=True)\n",
        "\n",
        "# Datasets\n",
        "datasets_rf = [\"KNN_L\", \"KNN_R\", \"Iterative_L\", \"Iterative_R\"]\n",
        "datasets_boosting = [\"Original_L\", \"Original_R\", \"KNN_L\", \"KNN_R\", \"Iterative_L\", \"Iterative_R\"]\n",
        "\n",
        "# Bone group definitions\n",
        "bone_groups = {\n",
        "    \"Clavicle\": [\"Clavicle maximum length\", \"Clavicle sagittal diameter at midshaft\", \"Clavicle vertical diameter at midshaft\"],\n",
        "    \"Scapula\": [\"Scapula height\", \"Scapula breadth\"],\n",
        "    \"Humerus\": [\"Humerus maximum length\", \"Humerus epicondylar breadth\", \"Humerus vertical diameter of head\",\n",
        "                \"Humerus maximum diameter at midshaft\", \"Humerus minimum diameter at midshaft\"],\n",
        "    \"Radius\": [\"Radius maximum length\", \"Radius sagittal diameter at midshaft\", \"Radius transverse diameter at midshaft\"],\n",
        "    \"Ulna\": [\"Ulna maximum length\", \"Ulna dorso-volar diameter\", \"Ulna transverse diameter\",\n",
        "             \"Ulna physiological length\", \"Ulna minimum circumference\"],\n",
        "    \"Femur\": [\"Femur maximum heigth\", \"Femur bicondylar length\", \"Femur epicondylar breadth\",\n",
        "              \"Femur maximum head diameter\", \"Femur sagittal subtrochanteric diameter\",\n",
        "              \"Femur transverse subtrochanteric diameter\", \"Femur sagittal midshaft diameter\",\n",
        "              \"Femur transverse midshaft diameter\", \"Femur midshaft circumference\"],\n",
        "    \"Tibia\": [\"Tibia length\", \"Tibia maximum proximal epiphyseal breadth\", \"Tibia maximum distal epiphyseal breadth\",\n",
        "              \"Tibia maximum diameter at the nutrient foramen\", \"Tibia transverse diameter at the nutrient foramen\",\n",
        "              \"Tibia circumference at the nutrient foramen\"],\n",
        "    \"Fibula\": [\"Fibula maximum length\", \"Fibula maximum diameter at midshaft\"],\n",
        "    \"Calcaneus\": [\"Calcaneus maximum length\", \"Calcaneus middle breadth\"]\n",
        "}\n",
        "\n",
        "# Loop through datasets and train/export models\n",
        "for dataset_name, df in datasets.items():\n",
        "    y = df[\"Pelvis Sex\"]\n",
        "\n",
        "    for group_name, features in bone_groups.items():\n",
        "        valid_features = [f for f in features if f in df.columns]\n",
        "        if not valid_features:\n",
        "            continue\n",
        "\n",
        "        X = df[valid_features].dropna()\n",
        "        y_subset = y.loc[X.index]\n",
        "\n",
        "        if len(X) < 2 or len(np.unique(y_subset)) < 2:\n",
        "            continue\n",
        "\n",
        "        for model_name in [\"XGBoost\", \"LightGBM\", \"RandomForest\"]:\n",
        "            if model_name == \"RandomForest\" and dataset_name not in datasets_rf:\n",
        "                continue\n",
        "            if model_name in [\"XGBoost\", \"LightGBM\"] and dataset_name not in datasets_boosting:\n",
        "                continue\n",
        "\n",
        "            model = classifiers[model_name]\n",
        "            model.fit(X, y_subset)\n",
        "\n",
        "            filename = f\"{model_name}_{group_name}_{dataset_name}.pkl\"\n",
        "            file_path = os.path.join(boosted_model_folder, filename)\n",
        "            joblib.dump(model, file_path)\n",
        "            print(f\"Exported: {file_path}\")\n"
      ],
      "metadata": {
        "id": "M9AjUnmAvSrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Test Pickled XGBoost, LightGBM, and RandomForest Models\n"
      ],
      "metadata": {
        "id": "ATqLDF-iICrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Path to the pickled models\n",
        "model_dir = \"/content/drive/MyDrive/Dion-results/Exported_Pickled_BoostedModels\"\n",
        "\n",
        "# Load datasets again (already preprocessed in earlier cells)\n",
        "left_bones_path = \"/content/drive/MyDrive/Dion-data/Cleaned_Left_Bones.csv\"\n",
        "right_bones_path = \"/content/drive/MyDrive/Dion-data/Cleaned_Right_Bones.csv\"\n",
        "df_mf_left_bones = pd.read_csv(left_bones_path)\n",
        "df_mf_right_bones = pd.read_csv(right_bones_path)\n",
        "\n",
        "df_mf_left_bones = df_mf_left_bones.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_mf_right_bones = df_mf_right_bones.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_mf_left_bones[\"Pelvis Sex\"] = LabelEncoder().fit_transform(df_mf_left_bones[\"Pelvis Sex\"])\n",
        "df_mf_right_bones[\"Pelvis Sex\"] = LabelEncoder().fit_transform(df_mf_right_bones[\"Pelvis Sex\"])\n",
        "\n",
        "# Load imputed datasets (KNN & Iterative)\n",
        "from sklearn.impute import KNNImputer, IterativeImputer\n",
        "independent_vars = [col for col in df_mf_left_bones.columns if col != \"Pelvis Sex\"]\n",
        "knn_imputer = KNNImputer(n_neighbors=3)\n",
        "iter_imputer = IterativeImputer(max_iter=1000, random_state=42)\n",
        "\n",
        "datasets = {\n",
        "    \"Original_L\": df_mf_left_bones.copy(),\n",
        "    \"Original_R\": df_mf_right_bones.copy(),\n",
        "    \"KNN_L\": df_mf_left_bones.copy(),\n",
        "    \"KNN_R\": df_mf_right_bones.copy(),\n",
        "    \"Iterative_L\": df_mf_left_bones.copy(),\n",
        "    \"Iterative_R\": df_mf_right_bones.copy(),\n",
        "}\n",
        "datasets[\"KNN_L\"][independent_vars] = knn_imputer.fit_transform(datasets[\"KNN_L\"][independent_vars])\n",
        "datasets[\"KNN_R\"][independent_vars] = knn_imputer.fit_transform(datasets[\"KNN_R\"][independent_vars])\n",
        "datasets[\"Iterative_L\"][independent_vars] = iter_imputer.fit_transform(datasets[\"Iterative_L\"][independent_vars])\n",
        "datasets[\"Iterative_R\"][independent_vars] = iter_imputer.fit_transform(datasets[\"Iterative_R\"][independent_vars])\n",
        "\n",
        "# Bone group definitions\n",
        "bone_groups = {\n",
        "    \"Clavicle\": [\"Clavicle maximum length\", \"Clavicle sagittal diameter at midshaft\", \"Clavicle vertical diameter at midshaft\"],\n",
        "    \"Scapula\": [\"Scapula height\", \"Scapula breadth\"],\n",
        "    \"Humerus\": [\"Humerus maximum length\", \"Humerus epicondylar breadth\", \"Humerus vertical diameter of head\",\n",
        "                \"Humerus maximum diameter at midshaft\", \"Humerus minimum diameter at midshaft\"],\n",
        "    \"Radius\": [\"Radius maximum length\", \"Radius sagittal diameter at midshaft\", \"Radius transverse diameter at midshaft\"],\n",
        "    \"Ulna\": [\"Ulna maximum length\", \"Ulna dorso-volar diameter\", \"Ulna transverse diameter\",\n",
        "             \"Ulna physiological length\", \"Ulna minimum circumference\"],\n",
        "    \"Femur\": [\"Femur maximum heigth\", \"Femur bicondylar length\", \"Femur epicondylar breadth\",\n",
        "              \"Femur maximum head diameter\", \"Femur sagittal subtrochanteric diameter\",\n",
        "              \"Femur transverse subtrochanteric diameter\", \"Femur sagittal midshaft diameter\",\n",
        "              \"Femur transverse midshaft diameter\", \"Femur midshaft circumference\"],\n",
        "    \"Tibia\": [\"Tibia length\", \"Tibia maximum proximal epiphyseal breadth\", \"Tibia maximum distal epiphyseal breadth\",\n",
        "              \"Tibia maximum diameter at the nutrient foramen\", \"Tibia transverse diameter at the nutrient foramen\",\n",
        "              \"Tibia circumference at the nutrient foramen\"],\n",
        "    \"Fibula\": [\"Fibula maximum length\", \"Fibula maximum diameter at midshaft\"],\n",
        "    \"Calcaneus\": [\"Calcaneus maximum length\", \"Calcaneus middle breadth\"]\n",
        "}\n",
        "\n",
        "# Evaluate all models\n",
        "results = []\n",
        "\n",
        "for filename in os.listdir(model_dir):\n",
        "    if not filename.endswith(\".pkl\"):\n",
        "        continue\n",
        "\n",
        "    model_path = os.path.join(model_dir, filename)\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "    try:\n",
        "        model_name, bone_group, dataset_name = filename.replace(\".pkl\", \"\").split(\"_\", 2)\n",
        "    except ValueError:\n",
        "        print(f\"Skipping invalid filename: {filename}\")\n",
        "        continue\n",
        "\n",
        "    if dataset_name not in datasets:\n",
        "        print(f\"Dataset {dataset_name} not found for model {filename}\")\n",
        "        continue\n",
        "\n",
        "    df = datasets[dataset_name]\n",
        "    if bone_group not in bone_groups:\n",
        "        print(f\"Bone group {bone_group} not in defined groups for {filename}\")\n",
        "        continue\n",
        "\n",
        "    features = [f for f in bone_groups[bone_group] if f in df.columns]\n",
        "    if not features:\n",
        "        print(f\"No valid features in {filename}\")\n",
        "        continue\n",
        "\n",
        "    X = df[features].dropna()\n",
        "    y = df.loc[X.index, \"Pelvis Sex\"]\n",
        "\n",
        "    if len(X) < 2 or len(np.unique(y)) < 2:\n",
        "        continue\n",
        "\n",
        "    y_pred = model.predict(X)\n",
        "    acc = accuracy_score(y, y_pred)\n",
        "    results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Bone Group\": bone_group,\n",
        "        \"Dataset\": dataset_name,\n",
        "        \"Accuracy\": acc\n",
        "    })\n",
        "\n",
        "# Display summary\n",
        "df_results = pd.DataFrame(results).sort_values(by=\"Accuracy\", ascending=False)\n",
        "print(df_results.sample(50))\n"
      ],
      "metadata": {
        "id": "sEFB-7IqH6Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample CSV file"
      ],
      "metadata": {
        "id": "kr3-YCIZMDvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Example: Humerus bone group (used by many models)\n",
        "sample_data = {\n",
        "    \"Humerus maximum length\": [310.0, 280.5],\n",
        "    \"Humerus epicondylar breadth\": [66.2, 58.3],\n",
        "    \"Humerus vertical diameter of head\": [43.1, 39.8],\n",
        "    \"Humerus maximum diameter at midshaft\": [23.0, 20.7],\n",
        "    \"Humerus minimum diameter at midshaft\": [20.1, 18.9]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df_sample = pd.DataFrame(sample_data)\n",
        "\n",
        "# Define file path\n",
        "output_path = \"/content/sample_data_for_prediction.csv\"\n",
        "\n",
        "# Save CSV\n",
        "df_sample.to_csv(output_path, index=False)\n",
        "print(f\"Sample CSV saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "eIGenAzLIZBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tcfbNB-RMG05"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}